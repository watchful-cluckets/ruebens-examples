{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognizer Demo with ScienceOps\n",
    "Deploying an image tagging model using neural networks + Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## VGG16 model for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Paper here](https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3)\n",
    "\n",
    "This is the [Keras](http://keras.io/) model of the 16-layer network used by the VGG team in the ILSVRC-2014 competition.\n",
    "\n",
    "It has been obtained by directly converting the [Caffe model](https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md) provived by the authors.\n",
    "\n",
    "Details about the network architecture can be found in the following arXiv paper:\n",
    "\n",
    "    Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "    K. Simonyan, A. Zisserman\n",
    "    arXiv:1409.1556\n",
    "    \n",
    "\n",
    "In the paper, the VGG-16 model is denoted as configuration `D`. It achieves 7.5% top-5 error on ILSVRC-2012-val, 7.4% top-5 error on ILSVRC-2012-test.\n",
    "\n",
    "Please cite the paper if you use the models.\n",
    "\n",
    "### Contents:\n",
    "\n",
    "model and usage demo: see `vgg-16_keras.py`\n",
    "\n",
    "weights: [vgg16_weights.h5](https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the weights from this link: https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing and put them in a directory called `data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T10:18:55.892207",
     "start_time": "2016-11-08T10:18:55.770383"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\r\n",
      "├── female_blog_list.txt\r\n",
      "├── intro_to_ann.csv\r\n",
      "├── male_blog_list.txt\r\n",
      "├── mnist.pkl.gz\r\n",
      "├── pig.jpg\r\n",
      "├── rt-polarity.neg\r\n",
      "├── rt-polarity.pos\r\n",
      "└── vgg16_weights.h5\r\n",
      "\r\n",
      "0 directories, 8 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T10:19:05.859007",
     "start_time": "2016-11-08T10:19:02.628439"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ken Cavagnolo \n",
      "last updated: Tue Nov 08 2016 \n",
      "\n",
      "CPython 2.7.12\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.2\n",
      "scipy 0.18.1\n",
      "pandas 0.19.0\n",
      "sklearn 0.18\n",
      "theano 0.8.2\n",
      "keras 1.1.0\n",
      "tensorflow 0.10.0rc0\n",
      "matplotlib 1.5.3\n",
      "plotly 1.12.9\n",
      "\n",
      "compiler   : GCC 4.4.7 20120313 (Red Hat 4.4.7-1)\n",
      "system     : Linux\n",
      "release    : 4.4.0-42-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : ubuntu\n",
      "Git hash   : ac1755e7e0c839e42c71d4577b9a246ce92e1477\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# basics #\n",
    "##########\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import itertools\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "###########\n",
    "# science #\n",
    "###########\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rseed = random.seed(42)\n",
    "np.random.seed(rseed)\n",
    "\n",
    "######\n",
    "# ml #\n",
    "######\n",
    "\n",
    "import theano as thno\n",
    "import keras as krs\n",
    "import tensorflow as tf\n",
    "\n",
    "###################\n",
    "# sklearn tooling #\n",
    "###################\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import grid_search\n",
    "from sklearn import pipeline\n",
    "from sklearn import feature_selection\n",
    "\n",
    "#################\n",
    "# visualization #\n",
    "#################\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "mpl.rcParams['figure.figsize']=(12.0,4.0)\n",
    "%matplotlib inline\n",
    "\n",
    "############\n",
    "# sys info #\n",
    "############\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Ken Cavagnolo\" -n -u -v -m -h -g -p numpy,scipy,pandas,sklearn,theano,keras,tensorflow,\\\n",
    "matplotlib,plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T10:19:44.532509",
     "start_time": "2016-11-08T10:19:41.631265"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named cv2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1e670c5ec782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cv2"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Munging our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = [\" \".join(row.split(' ')[1:]) for row in open(\"./labels.txt\").read().strip().split('\\n')]\n",
    "im = cv2.resize(cv2.imread('images/pig.jpg'), (224, 224)).astype(np.float32)\n",
    "# im = cv2.resize(cv2.imread('images/pickup-truck.jpg'), (224, 224)).astype(np.float32)\n",
    "# im = cv2.resize(cv2.imread('images/cat.jpg'), (224, 224)).astype(np.float32)\n",
    "im[:,:,0] -= 103.939\n",
    "im[:,:,1] -= 116.779\n",
    "im[:,:,2] -= 123.68\n",
    "im = im.transpose((2,0,1))\n",
    "im = np.expand_dims(im, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test pretrained model\n",
    "model = VGG_16('data/vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = model.predict(im)\n",
    "pred = dict(zip(labels, model.predict_proba(im)[0]))\n",
    "best_guess = labels[np.argmax(out)]\n",
    "print \"It's a %s\" % best_guess\n",
    "print { \"guess\": \"It's a %s\" % best_guess}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/pig.jpg)\n",
    "\n",
    "<center><h3>`{\"guess\": \"hog, pig, grunter, squealer, Sus scrofa\"}`</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying to ScienceOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yhat import Yhat, YhatModel, preprocess\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "import base64\n",
    "\n",
    "class ImageRecognizer(YhatModel):\n",
    "    REQUIREMENTS = [\n",
    "        \"opencv\"\n",
    "    ]\n",
    "    @preprocess(in_type=dict, out_type=dict)\n",
    "    def execute(self, data):\n",
    "        img64 = data['image64']\n",
    "        binaryimg = base64.decodestring(img64)\n",
    "        pilImage = Image.open(StringIO(binaryimg))\n",
    "        image = np.array(pilImage)\n",
    "        resized_image = cv2.resize(image, (224, 224)).astype(np.float32)\n",
    "        resized_image[:,:,0] -= 103.939\n",
    "        resized_image[:,:,1] -= 116.779\n",
    "        resized_image[:,:,2] -= 123.68\n",
    "        resized_image = resized_image.transpose((2,0,1))\n",
    "        resized_image = np.expand_dims(resized_image, axis=0)\n",
    "\n",
    "        out = model.predict(resized_image)\n",
    "        pred = dict(zip(labels, model.predict_proba(im)[0]))\n",
    "        best_guess = labels[np.argmax(out)]\n",
    "        print \"It's a %s\" % best_guess\n",
    "        return { \"guess\": best_guess }\n",
    "\n",
    "\n",
    "testdata = {\n",
    "    \"image64\": open('./test-image.base64', 'rb').read()\n",
    "}\n",
    "print ImageRecognizer().execute(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yh = Yhat(USERNAME, APIKEY, URL)\n",
    "yh.deploy(\"ImageRecognizer\", ImageRecognizer, globals(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
